{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "use envfinal kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helsinki-NLP/opus-mt-ko-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_text = 'A submersible of Eliksni design descends into Titan\\'s methane ocean, revealing an alien landscape of coral. Three figures, Fenchurch, Chalco, and Lisbon, explore the area using mechanical technology to regulate water pressure. They come across the remains of a creature called TKO-300, which shows signs of mitosis and has the ability to absorb knowledge. Fenchurch and Chalco\\'s fireteam receives recommendations on how to handle the remains, with Chalco suggesting quarantine and limited exposure. They also discuss a talisman that, if it glows white, indicates danger or memory loss. The submersible continues to descend, and they discover that they are investigating the ritualistic resurrection of Oryx, the Taken King. Chalco explains that the Lucent Brood attempted to combine Hive necromancy with a Ghost\\'s power, resulting in Oryx\\'s dismembered but still-active body. Fenchurch, Lisbon, and Chalco are the only team to have visited this site, and they are tasked with bringing back samples for further analysis.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
      "\n",
      "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-ko-en.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n",
      "c:\\Users\\knigh\\anaconda3\\envs\\envfinal\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-ko-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load model directly\n",
    "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ko-en\")\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-ko-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'There are other reasons why they care about love, love amongst others, love amongst other people, love amongst others, love amongst themselves, love amongst others, love amongst others, love amongst themselves, love amongst others, love amongst themselves, love amongst themselves, love amongst themselves, love amongst others, love amongst others and love amongst others.'}]\n"
     ]
    }
   ],
   "source": [
    "result = pipe(src_text, max_length=600)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helsinki-NLP/opus-mt-tc-big-en-ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': '中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 한국어 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文  中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文 中文  中文 中文 中文  中文 中文 中文 中文 中文 中文 中文 中文 中文  中文 中文 中文  中文 中文 中文 中文 中'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-tc-big-en-ko\")\n",
    "\n",
    "src_text = 'A submersible of Eliksni design descends into Titan\\'s methane ocean, revealing an alien landscape of coral. Three figures, Fenchurch, Chalco, and Lisbon, explore the area using mechanical technology to regulate water pressure. They come across the remains of a creature called TKO-300, which shows signs of mitosis and has the ability to absorb knowledge. Fenchurch and Chalco\\'s fireteam receives recommendations on how to handle the remains, with Chalco suggesting quarantine and limited exposure. They also discuss a talisman that, if it glows white, indicates danger or memory loss. The submersible continues to descend, and they discover that they are investigating the ritualistic resurrection of Oryx, the Taken King. Chalco explains that the Lucent Brood attempted to combine Hive necromancy with a Ghost\\'s power, resulting in Oryx\\'s dismembered but still-active body. Fenchurch, Lisbon, and Chalco are the only team to have visited this site, and they are tasked with bringing back samples for further analysis.'\n",
    "\n",
    "result = pipe(src_text, max_length=600)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NHNDQ/nllb-finetuned-ko2en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4484aa5ae943e89fb02959a31e4bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/921 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Could not load model NHNDQ/nllb-finetuned-ko2en with any of the following classes: (<class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSeq2SeqLM'>,).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pipe \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39;49m\u001b[39mtranslation\u001b[39;49m\u001b[39m\"\u001b[39;49m, model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mNHNDQ/nllb-finetuned-ko2en\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m result \u001b[39m=\u001b[39m pipe(src_text, max_length\u001b[39m=\u001b[39m\u001b[39m600\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(result)\n",
      "File \u001b[1;32mc:\\Users\\knigh\\anaconda3\\envs\\envfinal\\lib\\site-packages\\transformers\\pipelines\\__init__.py:788\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m framework \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    787\u001b[0m     model_classes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[1;32m--> 788\u001b[0m     framework, model \u001b[39m=\u001b[39m infer_framework_load_model(\n\u001b[0;32m    789\u001b[0m         model,\n\u001b[0;32m    790\u001b[0m         model_classes\u001b[39m=\u001b[39;49mmodel_classes,\n\u001b[0;32m    791\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m    792\u001b[0m         framework\u001b[39m=\u001b[39;49mframework,\n\u001b[0;32m    793\u001b[0m         task\u001b[39m=\u001b[39;49mtask,\n\u001b[0;32m    794\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs,\n\u001b[0;32m    795\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[0;32m    796\u001b[0m     )\n\u001b[0;32m    798\u001b[0m model_config \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\n\u001b[0;32m    799\u001b[0m hub_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32mc:\\Users\\knigh\\anaconda3\\envs\\envfinal\\lib\\site-packages\\transformers\\pipelines\\base.py:278\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    277\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 278\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not load model \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m with any of the following classes: \u001b[39m\u001b[39m{\u001b[39;00mclass_tuple\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m \u001b[39mif\u001b[39;00m framework \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    281\u001b[0m     framework \u001b[39m=\u001b[39m infer_framework(model\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Could not load model NHNDQ/nllb-finetuned-ko2en with any of the following classes: (<class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSeq2SeqLM'>,)."
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"translation\", model=\"NHNDQ/nllb-finetuned-ko2en\")\n",
    "result = pipe(src_text, max_length=600)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349911209768445db06dfebc79ac3703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\knigh\\anaconda3\\envs\\envfinal\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\knigh\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 1049419776 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoTokenizer, AutoModelForSeq2SeqLM\n\u001b[0;32m      4\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mNHNDQ/nllb-finetuned-ko2en\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m model \u001b[39m=\u001b[39m AutoModelForSeq2SeqLM\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mNHNDQ/nllb-finetuned-ko2en\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\knigh\\anaconda3\\envs\\envfinal\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:493\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    492\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 493\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[0;32m    494\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    495\u001b[0m     )\n\u001b[0;32m    496\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    497\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    498\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    499\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\knigh\\anaconda3\\envs\\envfinal\\lib\\site-packages\\transformers\\modeling_utils.py:2629\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2626\u001b[0m \u001b[39mif\u001b[39;00m from_pt:\n\u001b[0;32m   2627\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_sharded \u001b[39mand\u001b[39;00m state_dict \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2628\u001b[0m         \u001b[39m# Time to load the checkpoint\u001b[39;00m\n\u001b[1;32m-> 2629\u001b[0m         state_dict \u001b[39m=\u001b[39m load_state_dict(resolved_archive_file)\n\u001b[0;32m   2631\u001b[0m     \u001b[39m# set dtype to instantiate the model under:\u001b[39;00m\n\u001b[0;32m   2632\u001b[0m     \u001b[39m# 1. If torch_dtype is not None, we use that dtype\u001b[39;00m\n\u001b[0;32m   2633\u001b[0m     \u001b[39m# 2. If torch_dtype is \"auto\", we auto-detect dtype from the loaded state_dict, by checking its first\u001b[39;00m\n\u001b[0;32m   2634\u001b[0m     \u001b[39m#    weights entry that is of a floating type - we assume all floating dtype weights are of the same dtype\u001b[39;00m\n\u001b[0;32m   2635\u001b[0m     \u001b[39m# we also may have config.torch_dtype available, but we won't rely on it till v5\u001b[39;00m\n\u001b[0;32m   2636\u001b[0m     dtype_orig \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\knigh\\anaconda3\\envs\\envfinal\\lib\\site-packages\\transformers\\modeling_utils.py:458\u001b[0m, in \u001b[0;36mload_state_dict\u001b[1;34m(checkpoint_file)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[39melif\u001b[39;00m metadata[\u001b[39m\"\u001b[39m\u001b[39mformat\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    455\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    456\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion from a \u001b[39m\u001b[39m{\u001b[39;00mmetadata[\u001b[39m'\u001b[39m\u001b[39mformat\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m safetensors archive to PyTorch is not implemented yet.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    457\u001b[0m         )\n\u001b[1;32m--> 458\u001b[0m     \u001b[39mreturn\u001b[39;00m safe_load_file(checkpoint_file)\n\u001b[0;32m    459\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mload(checkpoint_file, map_location\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\knigh\\anaconda3\\envs\\envfinal\\lib\\site-packages\\safetensors\\torch.py:311\u001b[0m, in \u001b[0;36mload_file\u001b[1;34m(filename, device)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[39mwith\u001b[39;00m safe_open(filename, framework\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, device\u001b[39m=\u001b[39mdevice) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    310\u001b[0m     \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m f\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m--> 311\u001b[0m         result[k] \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39;49mget_tensor(k)\n\u001b[0;32m    312\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 1049419776 bytes."
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"NHNDQ/nllb-finetuned-ko2en\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"NHNDQ/nllb-finetuned-ko2en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Translation API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use ClovisBrayI kernel\n",
    "# Imports the Google Cloud Translation library\n",
    "from google.cloud import translate\n",
    "\n",
    "YOUR_PROJECT_ID = 'plated-monolith-394902'\n",
    "\n",
    "# Initialize Translation client\n",
    "def translate_text(\n",
    "    text: str = \"YOUR_TEXT_TO_TRANSLATE\", project_id: str = \"YOUR_PROJECT_ID\"\n",
    ") -> translate.TranslationServiceClient:\n",
    "    \"\"\"Translating Text.\"\"\"\n",
    "\n",
    "    client = translate.TranslationServiceClient()\n",
    "\n",
    "    location = \"global\"\n",
    "\n",
    "    parent = f\"projects/{project_id}/locations/{location}\"\n",
    "\n",
    "    # Translate text from English to French\n",
    "    # Detail on supported types can be found here:\n",
    "    # https://cloud.google.com/translate/docs/supported-formats\n",
    "    response = client.translate_text(\n",
    "        request={\n",
    "            \"parent\": parent,\n",
    "            \"contents\": [text],\n",
    "            \"mime_type\": \"text/plain\",  # mime types: text/plain, text/html\n",
    "            \"source_language_code\": \"en-US\",\n",
    "            \"target_language_code\": \"fr\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Display the translation for each input text provided\n",
    "    for translation in response.translations:\n",
    "        print(f\"Translated text: {translation.translated_text}\")\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m translate_text(\u001b[39m'\u001b[39;49m\u001b[39mhis name is Fenchurch\u001b[39;49m\u001b[39m'\u001b[39;49m, YOUR_PROJECT_ID)\n",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m, in \u001b[0;36mtranslate_text\u001b[1;34m(text, project_id)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtranslate_text\u001b[39m(\n\u001b[0;32m      9\u001b[0m     text: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mYOUR_TEXT_TO_TRANSLATE\u001b[39m\u001b[39m\"\u001b[39m, project_id: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mYOUR_PROJECT_ID\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m translate\u001b[39m.\u001b[39mTranslationServiceClient:\n\u001b[0;32m     11\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Translating Text.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     client \u001b[39m=\u001b[39m translate\u001b[39m.\u001b[39;49mTranslationServiceClient()\n\u001b[0;32m     15\u001b[0m     location \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mglobal\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     17\u001b[0m     parent \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mprojects/\u001b[39m\u001b[39m{\u001b[39;00mproject_id\u001b[39m}\u001b[39;00m\u001b[39m/locations/\u001b[39m\u001b[39m{\u001b[39;00mlocation\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\knigh\\anaconda3\\envs\\ClovisBrayI\\lib\\site-packages\\google\\cloud\\translate_v3\\services\\translation_service\\client.py:436\u001b[0m, in \u001b[0;36mTranslationServiceClient.__init__\u001b[1;34m(self, credentials, transport, client_options, client_info)\u001b[0m\n\u001b[0;32m    431\u001b[0m     credentials \u001b[39m=\u001b[39m google\u001b[39m.\u001b[39mauth\u001b[39m.\u001b[39m_default\u001b[39m.\u001b[39mget_api_key_credentials(\n\u001b[0;32m    432\u001b[0m         api_key_value\n\u001b[0;32m    433\u001b[0m     )\n\u001b[0;32m    435\u001b[0m Transport \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mget_transport_class(transport)\n\u001b[1;32m--> 436\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transport \u001b[39m=\u001b[39m Transport(\n\u001b[0;32m    437\u001b[0m     credentials\u001b[39m=\u001b[39;49mcredentials,\n\u001b[0;32m    438\u001b[0m     credentials_file\u001b[39m=\u001b[39;49mclient_options\u001b[39m.\u001b[39;49mcredentials_file,\n\u001b[0;32m    439\u001b[0m     host\u001b[39m=\u001b[39;49mapi_endpoint,\n\u001b[0;32m    440\u001b[0m     scopes\u001b[39m=\u001b[39;49mclient_options\u001b[39m.\u001b[39;49mscopes,\n\u001b[0;32m    441\u001b[0m     client_cert_source_for_mtls\u001b[39m=\u001b[39;49mclient_cert_source_func,\n\u001b[0;32m    442\u001b[0m     quota_project_id\u001b[39m=\u001b[39;49mclient_options\u001b[39m.\u001b[39;49mquota_project_id,\n\u001b[0;32m    443\u001b[0m     client_info\u001b[39m=\u001b[39;49mclient_info,\n\u001b[0;32m    444\u001b[0m     always_use_jwt_access\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    445\u001b[0m     api_audience\u001b[39m=\u001b[39;49mclient_options\u001b[39m.\u001b[39;49mapi_audience,\n\u001b[0;32m    446\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\knigh\\anaconda3\\envs\\ClovisBrayI\\lib\\site-packages\\google\\cloud\\translate_v3\\services\\translation_service\\transports\\grpc.py:152\u001b[0m, in \u001b[0;36mTranslationServiceGrpcTransport.__init__\u001b[1;34m(self, host, credentials, credentials_file, scopes, channel, api_mtls_endpoint, client_cert_source, ssl_channel_credentials, client_cert_source_for_mtls, quota_project_id, client_info, always_use_jwt_access, api_audience)\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ssl_channel_credentials \u001b[39m=\u001b[39m grpc\u001b[39m.\u001b[39mssl_channel_credentials(\n\u001b[0;32m    148\u001b[0m                 certificate_chain\u001b[39m=\u001b[39mcert, private_key\u001b[39m=\u001b[39mkey\n\u001b[0;32m    149\u001b[0m             )\n\u001b[0;32m    151\u001b[0m \u001b[39m# The base transport sets the host, credentials and scopes\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m    153\u001b[0m     host\u001b[39m=\u001b[39;49mhost,\n\u001b[0;32m    154\u001b[0m     credentials\u001b[39m=\u001b[39;49mcredentials,\n\u001b[0;32m    155\u001b[0m     credentials_file\u001b[39m=\u001b[39;49mcredentials_file,\n\u001b[0;32m    156\u001b[0m     scopes\u001b[39m=\u001b[39;49mscopes,\n\u001b[0;32m    157\u001b[0m     quota_project_id\u001b[39m=\u001b[39;49mquota_project_id,\n\u001b[0;32m    158\u001b[0m     client_info\u001b[39m=\u001b[39;49mclient_info,\n\u001b[0;32m    159\u001b[0m     always_use_jwt_access\u001b[39m=\u001b[39;49malways_use_jwt_access,\n\u001b[0;32m    160\u001b[0m     api_audience\u001b[39m=\u001b[39;49mapi_audience,\n\u001b[0;32m    161\u001b[0m )\n\u001b[0;32m    163\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grpc_channel:\n\u001b[0;32m    164\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grpc_channel \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mcreate_channel(\n\u001b[0;32m    165\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_host,\n\u001b[0;32m    166\u001b[0m         \u001b[39m# use the credentials which are saved\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m         ],\n\u001b[0;32m    178\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\knigh\\anaconda3\\envs\\ClovisBrayI\\lib\\site-packages\\google\\cloud\\translate_v3\\services\\translation_service\\transports\\base.py:103\u001b[0m, in \u001b[0;36mTranslationServiceTransport.__init__\u001b[1;34m(self, host, credentials, credentials_file, scopes, quota_project_id, client_info, always_use_jwt_access, api_audience, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m     credentials, _ \u001b[39m=\u001b[39m google\u001b[39m.\u001b[39mauth\u001b[39m.\u001b[39mload_credentials_from_file(\n\u001b[0;32m    100\u001b[0m         credentials_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mscopes_kwargs, quota_project_id\u001b[39m=\u001b[39mquota_project_id\n\u001b[0;32m    101\u001b[0m     )\n\u001b[0;32m    102\u001b[0m \u001b[39melif\u001b[39;00m credentials \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 103\u001b[0m     credentials, _ \u001b[39m=\u001b[39m google\u001b[39m.\u001b[39;49mauth\u001b[39m.\u001b[39;49mdefault(\n\u001b[0;32m    104\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mscopes_kwargs, quota_project_id\u001b[39m=\u001b[39;49mquota_project_id\n\u001b[0;32m    105\u001b[0m     )\n\u001b[0;32m    106\u001b[0m     \u001b[39m# Don't apply audience if the credentials file passed from user.\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(credentials, \u001b[39m\"\u001b[39m\u001b[39mwith_gdch_audience\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\google\\auth\\_default.py:692\u001b[0m, in \u001b[0;36mdefault\u001b[1;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[0;32m    684\u001b[0m             _LOGGER\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    685\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mNo project ID could be determined. Consider running \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    686\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m`gcloud config set project` or setting the \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    687\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39menvironment variable\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    688\u001b[0m                 environment_vars\u001b[39m.\u001b[39mPROJECT,\n\u001b[0;32m    689\u001b[0m             )\n\u001b[0;32m    690\u001b[0m         \u001b[39mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[1;32m--> 692\u001b[0m \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mDefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[1;31mDefaultCredentialsError\u001b[0m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information."
     ]
    }
   ],
   "source": [
    "translate_text('his name is Fenchurch', YOUR_PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ClovisBrayI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
